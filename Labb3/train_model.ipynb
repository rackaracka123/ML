{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "lookup_df = pd.read_csv(\"zone_lookup.csv\")\n",
    "\n",
    "DATEPARSE = \"%Y-%m-%d %H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, poly, min_max):\n",
    "    file_name = datetime.now().strftime(DATEPARSE)\n",
    "    dump(model, \"models/\" + file_name + \"_model.joblib\")\n",
    "    dump(poly, \"models/\" + file_name + \"_poly.joblib\")\n",
    "    dump(min_max, \"models/\" + file_name + \"_min_max.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Mean squared error: 92.57406133821512 Accuracy: 0.003460095925976736\n",
      "New best accuracy\n",
      "1: Mean squared error: 88.57688403234954 Accuracy: 0.004814531606774697\n",
      "New best accuracy\n",
      "2: Mean squared error: 94.50435319292427 Accuracy: 0.0013553999610413925\n",
      "3: Mean squared error: 80.67624269625807 Accuracy: 0.0174783765385641\n",
      "New best accuracy\n",
      "4: Mean squared error: 70.65385679564898 Accuracy: 0.0012311986297424138\n",
      "5: Mean squared error: 81.57863892454749 Accuracy: -0.0655656147755912\n",
      "6: Mean squared error: 78.38214931602552 Accuracy: 0.08648965622088\n",
      "New best accuracy\n",
      "7: Mean squared error: 55.21797078875144 Accuracy: 0.08079587422190593\n",
      "8: Mean squared error: 53.58047056101465 Accuracy: 0.07360135073133611\n",
      "9: Mean squared error: 71.6689257515843 Accuracy: 0.11328025858422608\n",
      "New best accuracy\n",
      "10: Mean squared error: 61.77138176011732 Accuracy: 0.18251452088906994\n",
      "New best accuracy\n",
      "11: Mean squared error: 77.25344726876142 Accuracy: 0.15123093102656404\n",
      "12: Mean squared error: 81.03639305357896 Accuracy: 0.11950878296943179\n",
      "13: Mean squared error: 74.39615196765047 Accuracy: 0.23053490572526558\n",
      "New best accuracy\n",
      "14: Mean squared error: 60.7698322066931 Accuracy: 0.2219457309337114\n",
      "15: Mean squared error: 82.68008203209406 Accuracy: 0.233096611701476\n",
      "New best accuracy\n",
      "16: Mean squared error: 61.16272074010526 Accuracy: 0.18622314737931067\n",
      "17: Mean squared error: 74.29685006976416 Accuracy: 0.20461035870998456\n",
      "18: Mean squared error: 51.53014650361147 Accuracy: 0.26870118582782065\n",
      "New best accuracy\n",
      "19: Mean squared error: 106.17687026758534 Accuracy: 0.19607109453759441\n",
      "20: Mean squared error: 87.40677734926429 Accuracy: 0.20392191520789482\n",
      "21: Mean squared error: 80.15674901026101 Accuracy: 0.1327332305903135\n",
      "22: Mean squared error: 79.86214447861842 Accuracy: 0.11868157967174875\n",
      "23: Mean squared error: 86.40392902259214 Accuracy: 0.1262331034576567\n",
      "24: Mean squared error: 71.90496547892461 Accuracy: 0.12616197072477575\n",
      "25: Mean squared error: 72.83014224778374 Accuracy: 0.1456134037924285\n",
      "26: Mean squared error: 84.26026819320424 Accuracy: 0.19344053266347627\n",
      "27: Mean squared error: 123.96941870459366 Accuracy: 0.16874260464710222\n",
      "28: Mean squared error: 229.18427362834782 Accuracy: -0.33160939347861373\n",
      "29: Mean squared error: 134.56445925676363 Accuracy: 0.2503060877370795\n",
      "30: Mean squared error: 116.65727842395147 Accuracy: 0.2515052503331615\n",
      "31: Mean squared error: 137.8132745121252 Accuracy: 0.1189368983938669\n",
      "32: Mean squared error: 73.62957643186382 Accuracy: 0.24687964750589997\n",
      "33: Mean squared error: 65.74456701320042 Accuracy: 0.18168613058077165\n",
      "34: Mean squared error: 52.014516840445474 Accuracy: 0.2844497797034413\n",
      "New best accuracy\n",
      "35: Mean squared error: 62.83679158730442 Accuracy: 0.1384608573171111\n",
      "36: Mean squared error: 55.70104621812678 Accuracy: 0.2374307496609368\n",
      "37: Mean squared error: 58.19539285334272 Accuracy: 0.3006193631606009\n",
      "New best accuracy\n",
      "38: Mean squared error: 85.37857424632955 Accuracy: 0.16397674732293155\n",
      "39: Mean squared error: 110.63741722464259 Accuracy: 0.2435732409503506\n",
      "40: Mean squared error: 125.23161173157168 Accuracy: 0.1747951503028493\n",
      "41: Mean squared error: 92.32786718658048 Accuracy: 0.2184898364126867\n",
      "42: Mean squared error: 79.39191681710047 Accuracy: 0.1344741092112226\n",
      "43: Mean squared error: 74.97098000284976 Accuracy: 0.1201604941142036\n",
      "44: Mean squared error: 78.33420445170047 Accuracy: 0.1453421363171158\n",
      "45: Mean squared error: 93.26448192503968 Accuracy: 0.0999446220489848\n",
      "46: Mean squared error: 80.00771730618543 Accuracy: 0.1986955824264538\n",
      "47: Mean squared error: 85.38107598335365 Accuracy: 0.22060711444439374\n",
      "48: Mean squared error: 96.59145188638227 Accuracy: 0.20297412942204718\n",
      "49: Mean squared error: 125.02841462443085 Accuracy: 0.19089005830101946\n",
      "50: Mean squared error: 128.88385517555017 Accuracy: 0.18365267021105336\n",
      "51: Mean squared error: 111.79489707327413 Accuracy: 0.2373892438681059\n",
      "52: Mean squared error: 75.10927335108859 Accuracy: 0.275560635582633\n",
      "53: Mean squared error: 68.9085135124243 Accuracy: 0.18599154834529474\n",
      "54: Mean squared error: 56.034578322526706 Accuracy: 0.1542598315872844\n",
      "55: Mean squared error: 71.204762609963 Accuracy: 0.08877178111878248\n",
      "56: Mean squared error: 48.51652709533499 Accuracy: 0.2569389924591744\n",
      "57: Mean squared error: 71.201784552992 Accuracy: -0.13619627223652708\n",
      "58: Mean squared error: 66.19900448279402 Accuracy: 0.18890481393935177\n",
      "59: Mean squared error: 71.29355370695573 Accuracy: -0.10217054947591198\n",
      "60: Mean squared error: 65.82902411486289 Accuracy: 0.2028152758544306\n",
      "61: Mean squared error: 83.2028319690692 Accuracy: 0.22721418292097073\n",
      "62: Mean squared error: 70.06295525028537 Accuracy: 0.18317672803697427\n",
      "63: Mean squared error: 64.26280854778976 Accuracy: 0.17470511034271696\n",
      "64: Mean squared error: 64.03052950832813 Accuracy: 0.14890340761838083\n",
      "65: Mean squared error: 70.26010467147127 Accuracy: -0.01162616814184747\n",
      "66: Mean squared error: 65.33624360234867 Accuracy: 0.033130751643791756\n",
      "67: Mean squared error: 64.06833595057505 Accuracy: 0.12950758426473707\n",
      "68: Mean squared error: 70.76098169279007 Accuracy: 0.19201109587146914\n",
      "69: Mean squared error: 83.74057818456714 Accuracy: 0.18104638825174724\n",
      "70: Mean squared error: 110.7646990255252 Accuracy: 0.21667735563801016\n",
      "71: Mean squared error: 122.15153274862031 Accuracy: 0.16589908347316884\n",
      "72: Mean squared error: 99.83504300960983 Accuracy: 0.22659969300995386\n",
      "73: Mean squared error: 88.07428328813414 Accuracy: 0.25414567787041775\n",
      "74: Mean squared error: 80.63715616104186 Accuracy: 0.17570723753700512\n",
      "75: Mean squared error: 66.78670166953138 Accuracy: 0.22194747390018288\n",
      "76: Mean squared error: 48.5312401740644 Accuracy: 0.24590060142335135\n",
      "77: Mean squared error: 93.46042632881553 Accuracy: 0.16003302316619417\n",
      "78: Mean squared error: 55.94768756845475 Accuracy: 0.1565950724958015\n",
      "79: Mean squared error: 54.201938576881865 Accuracy: 0.16766266072341574\n",
      "80: Mean squared error: 48.945888081919215 Accuracy: 0.12790389243301592\n",
      "81: Mean squared error: 60.39829307160431 Accuracy: 0.0780141107894855\n",
      "82: Mean squared error: 58.71162151728126 Accuracy: 0.02643711733118581\n",
      "83: Mean squared error: 50.98244145186378 Accuracy: 0.06665425055528928\n",
      "84: Mean squared error: 49.79235989302217 Accuracy: 0.03185237019060716\n",
      "85: Mean squared error: 60.29615033525671 Accuracy: 0.2037408379891783\n",
      "86: Mean squared error: 44.515906377420286 Accuracy: 0.22918315029505187\n",
      "87: Mean squared error: 49.713482995506354 Accuracy: 0.18660253997334697\n",
      "88: Mean squared error: 43.17114457920857 Accuracy: 0.19718598533061082\n",
      "89: Mean squared error: 43.00006200129829 Accuracy: 0.10129053520579712\n",
      "90: Mean squared error: 47.88763474340943 Accuracy: 0.15082842838065136\n",
      "91: Mean squared error: 52.28413823425849 Accuracy: 0.12949405954460247\n",
      "92: Mean squared error: 59.63772686090737 Accuracy: 0.14962601401028275\n",
      "93: Mean squared error: 64.20517155560765 Accuracy: 0.14868578519220044\n",
      "94: Mean squared error: 63.794401128143804 Accuracy: 0.22689087787211848\n",
      "95: Mean squared error: 61.633369198453416 Accuracy: 0.22569259582172674\n",
      "96: Mean squared error: 65.69409901163883 Accuracy: 0.27511476271195645\n",
      "97: Mean squared error: 75.54723027582797 Accuracy: 0.1362437457452359\n",
      "98: Mean squared error: 57.13797565375576 Accuracy: 0.21165478965712659\n",
      "99: Mean squared error: 59.92085118490323 Accuracy: 0.22714507145073326\n",
      "100: Mean squared error: 63.1477072797609 Accuracy: 0.20484183365230646\n",
      "101: Mean squared error: 59.637121349916434 Accuracy: 0.1755796355545528\n",
      "102: Mean squared error: 53.373978312617204 Accuracy: 0.23397469894390854\n",
      "103: Mean squared error: 46.31616327204544 Accuracy: 0.18324242185933337\n",
      "104: Mean squared error: 50.54021242602244 Accuracy: 0.04518250930477152\n",
      "105: Mean squared error: 50.51121016342872 Accuracy: 0.13140061034896877\n",
      "106: Mean squared error: 49.42380329219286 Accuracy: 0.02308292947543611\n",
      "107: Mean squared error: 46.80460056873065 Accuracy: 0.011096888498359547\n",
      "108: Mean squared error: 70.32191675554701 Accuracy: 0.1046773926307849\n",
      "109: Mean squared error: 62.83787558154421 Accuracy: 0.20493910512387925\n",
      "110: Mean squared error: 44.055786620226236 Accuracy: 0.12253345021169837\n",
      "111: Mean squared error: 47.98342729611761 Accuracy: 0.06507874782087697\n",
      "112: Mean squared error: 50.01261836003079 Accuracy: 0.07536261141042466\n",
      "113: Mean squared error: 45.80490242083525 Accuracy: 0.14326164044116263\n",
      "114: Mean squared error: 80.8895709179041 Accuracy: -0.09735345699380082\n",
      "115: Mean squared error: 62.32531468831811 Accuracy: 0.2503168559556135\n",
      "116: Mean squared error: 73.43154268257734 Accuracy: 0.24695322627599914\n",
      "117: Mean squared error: 101.24598790765297 Accuracy: 0.05240836872951249\n",
      "118: Mean squared error: 85.71301106315376 Accuracy: 0.2628519092297542\n",
      "119: Mean squared error: 92.4070907937192 Accuracy: 0.21435782959014504\n",
      "120: Mean squared error: 74.52372862310445 Accuracy: 0.26496497521578366\n",
      "121: Mean squared error: 81.62280227806696 Accuracy: 0.23902414616824708\n",
      "122: Mean squared error: 109.04554388583784 Accuracy: 0.10850213749783777\n",
      "123: Mean squared error: 51.233188989048934 Accuracy: 0.3733550574176996\n",
      "New best accuracy\n",
      "124: Mean squared error: 52.68897980344328 Accuracy: 0.3549869546597981\n",
      "125: Mean squared error: 48.535279217102115 Accuracy: 0.2804328819077816\n",
      "126: Mean squared error: 70.01887769098155 Accuracy: 0.2511772024111685\n",
      "127: Mean squared error: 110.46017666142176 Accuracy: 0.20593238254451995\n",
      "128: Mean squared error: 106.30173397801853 Accuracy: 0.24437155658258225\n",
      "129: Mean squared error: 113.8539643111262 Accuracy: 0.06275927109851587\n",
      "130: Mean squared error: 83.17219476070751 Accuracy: 0.17962880796308467\n",
      "131: Mean squared error: 80.66558828971124 Accuracy: 0.1864489793242936\n",
      "132: Mean squared error: 76.32135520341376 Accuracy: 0.14072210961467835\n",
      "133: Mean squared error: 69.56259554041229 Accuracy: 0.16307879154184612\n",
      "134: Mean squared error: 71.63098000323207 Accuracy: 0.20614965587179124\n",
      "135: Mean squared error: 91.16455680736655 Accuracy: 0.1517020882966188\n",
      "136: Mean squared error: 83.10413295085078 Accuracy: 0.266490033292067\n",
      "137: Mean squared error: 98.60616831103445 Accuracy: 0.2745171905868581\n",
      "138: Mean squared error: 98.44324785899818 Accuracy: 0.3113558906150081\n",
      "139: Mean squared error: 121.29350649290168 Accuracy: 0.22191658419117166\n",
      "140: Mean squared error: 69.77760544989869 Accuracy: 0.29949415942179014\n",
      "141: Mean squared error: 61.661272343171866 Accuracy: 0.25702417905883157\n",
      "142: Mean squared error: 57.247673211921324 Accuracy: 0.17993596318879712\n",
      "143: Mean squared error: 46.55581568735084 Accuracy: 0.19118310557890783\n",
      "144: Mean squared error: 44.283061596222744 Accuracy: 0.2177297697497319\n",
      "145: Mean squared error: 41.794697790537725 Accuracy: 0.2805390444315533\n",
      "146: Mean squared error: 49.76665306206318 Accuracy: 0.2366753989195095\n",
      "147: Mean squared error: 51.48579937740074 Accuracy: 0.1353251069514484\n",
      "148: Mean squared error: 75.41020240333759 Accuracy: 0.17677600626131518\n",
      "149: Mean squared error: 92.91082745888188 Accuracy: 0.18438732689668502\n",
      "150: Mean squared error: 111.49603864623036 Accuracy: 0.21463249840315268\n",
      "151: Mean squared error: 111.00864192335959 Accuracy: 0.0869409389056034\n",
      "152: Mean squared error: 98.33105934157655 Accuracy: 0.169625726180476\n",
      "153: Mean squared error: 87.8116425686402 Accuracy: 0.15158764471299901\n",
      "154: Mean squared error: 88.3297197389626 Accuracy: 0.13070540002674325\n",
      "155: Mean squared error: 76.9016903689327 Accuracy: 0.11995984837281415\n",
      "156: Mean squared error: 83.75506787015168 Accuracy: 0.0137709512071853\n",
      "157: Mean squared error: 73.5011426660792 Accuracy: 0.06905548251469573\n",
      "158: Mean squared error: 88.14523693095019 Accuracy: 0.058025004767023214\n",
      "159: Mean squared error: 92.24578633867121 Accuracy: 0.1402064685648743\n",
      "160: Mean squared error: 91.19127937689542 Accuracy: 0.2124762118223288\n",
      "161: Mean squared error: 128.0077797304851 Accuracy: 0.16692883126460178\n",
      "162: Mean squared error: 95.70320422581396 Accuracy: 0.23989446517371282\n",
      "163: Mean squared error: 77.72689478444612 Accuracy: 0.18946311560371576\n",
      "164: Mean squared error: 64.24263387515387 Accuracy: 0.1464370568074217\n",
      "165: Mean squared error: 54.50758486027642 Accuracy: 0.13761227915016316\n",
      "166: Mean squared error: 46.35450424029965 Accuracy: 0.2221339132465765\n",
      "167: Mean squared error: 44.452866707582466 Accuracy: 0.22631430743091463\n",
      "168: Mean squared error: 44.79565679223784 Accuracy: 0.18020308241409455\n",
      "169: Mean squared error: 69.64608516659415 Accuracy: -0.06159630694613161\n",
      "170: Mean squared error: 67.05136166805092 Accuracy: 0.0796658115875929\n",
      "171: Mean squared error: 54.67741409802204 Accuracy: 0.17604317671246228\n",
      "172: Mean squared error: 69.12117418429843 Accuracy: 0.24305073788716136\n",
      "173: Mean squared error: 90.44544264847683 Accuracy: 0.23502043686818774\n",
      "174: Mean squared error: 93.50932432242853 Accuracy: 0.15375251220098296\n",
      "175: Mean squared error: 92.19113062610931 Accuracy: 0.14078085690312214\n",
      "176: Mean squared error: 92.82959964423745 Accuracy: 0.1086011759002451\n",
      "177: Mean squared error: 75.42281853808328 Accuracy: 0.11078143008675545\n",
      "178: Mean squared error: 78.72635219557071 Accuracy: 0.12309616798777823\n",
      "179: Mean squared error: 79.52595173337492 Accuracy: 0.09576565972488449\n",
      "180: Mean squared error: 75.17589736509419 Accuracy: 0.17412919889505607\n",
      "181: Mean squared error: 82.57962188609531 Accuracy: 0.19340663964268334\n",
      "182: Mean squared error: 83.73652661081242 Accuracy: 0.17274741233694135\n",
      "183: Mean squared error: 95.90316698734676 Accuracy: 0.2527640050480864\n",
      "184: Mean squared error: 130.71025779218994 Accuracy: 0.08369310141045883\n",
      "185: Mean squared error: 117.23579690392138 Accuracy: 0.23917499305712964\n",
      "186: Mean squared error: 91.38990194329509 Accuracy: 0.21066536635136246\n",
      "187: Mean squared error: 81.6552710516298 Accuracy: 0.25058843932988306\n",
      "188: Mean squared error: 61.54197038606069 Accuracy: 0.21798384170831897\n",
      "189: Mean squared error: 64.79329543358759 Accuracy: 0.0999032505694103\n",
      "190: Mean squared error: 60.41712054900726 Accuracy: 0.16481886245481026\n",
      "191: Mean squared error: 57.78891736973002 Accuracy: 0.0209125515071652\n",
      "192: Mean squared error: 71.62455454020177 Accuracy: 0.1363567765660747\n",
      "193: Mean squared error: 58.23585564962167 Accuracy: 0.1127228395557277\n",
      "194: Mean squared error: 61.283959460274296 Accuracy: 0.14007026454715088\n",
      "195: Mean squared error: 84.51124080867844 Accuracy: -0.04324525270210522\n",
      "196: Mean squared error: 62.0979197909445 Accuracy: -0.053331330084656736\n",
      "197: Mean squared error: 76.14280116431424 Accuracy: 0.25628254851093946\n",
      "198: Mean squared error: 90.77952524959855 Accuracy: 0.2236417092574262\n",
      "199: Mean squared error: 93.42626935653446 Accuracy: 0.2080199758710064\n",
      "200: Mean squared error: 99.10845916678512 Accuracy: 0.13227519190559878\n",
      "201: Mean squared error: 86.50818790359436 Accuracy: 0.1091649711139907\n",
      "202: Mean squared error: 80.03200713607438 Accuracy: 0.13681089688918058\n",
      "203: Mean squared error: 80.61681975293438 Accuracy: 0.08149358766661008\n",
      "204: Mean squared error: 82.00700249692741 Accuracy: 0.08577238744385407\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rackaracka\\Documents\\repos\\ML\\Labb3\\train_model.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/train_model.ipynb#ch0000003?line=16'>17</a>\u001b[0m scaled \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39mfit_transform(min_max\u001b[39m.\u001b[39mfit_transform(X_green\u001b[39m.\u001b[39mvalues))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/train_model.ipynb#ch0000003?line=18'>19</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(scaled, y_green\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(), test_size \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/train_model.ipynb#ch0000003?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mpartial_fit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/train_model.ipynb#ch0000003?line=22'>23</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/train_model.ipynb#ch0000003?line=24'>25</a>\u001b[0m score \u001b[39m=\u001b[39m r2_score(y_test, y_pred)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1447\u001b[0m, in \u001b[0;36mBaseSGDRegressor.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1421'>1422</a>\u001b[0m \u001b[39m\"\"\"Perform one epoch of stochastic gradient descent on given samples.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1422'>1423</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1423'>1424</a>\u001b[0m \u001b[39mInternally, this method uses ``max_iter = 1``. Therefore, it is not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1443'>1444</a>\u001b[0m \u001b[39m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1444'>1445</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1445'>1446</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params(for_partial_fit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1446'>1447</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1447'>1448</a>\u001b[0m     X,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1448'>1449</a>\u001b[0m     y,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1449'>1450</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1450'>1451</a>\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1451'>1452</a>\u001b[0m     loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1452'>1453</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1453'>1454</a>\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1454'>1455</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1455'>1456</a>\u001b[0m     coef_init\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1456'>1457</a>\u001b[0m     intercept_init\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1457'>1458</a>\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1415\u001b[0m, in \u001b[0;36mBaseSGDRegressor._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1411'>1412</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_coef \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_features, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1412'>1413</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_intercept \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1414'>1415</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_regressor(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1415'>1416</a>\u001b[0m     X, y, alpha, C, loss, learning_rate, sample_weight, max_iter\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1416'>1417</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1418'>1419</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1618\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit_regressor\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1614'>1615</a>\u001b[0m     average_coef \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Not used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1615'>1616</a>\u001b[0m     average_intercept \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m]  \u001b[39m# Not used\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1617'>1618</a>\u001b[0m coef, intercept, average_coef, average_intercept, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _plain_sgd(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1618'>1619</a>\u001b[0m     coef,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1619'>1620</a>\u001b[0m     intercept[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1620'>1621</a>\u001b[0m     average_coef,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1621'>1622</a>\u001b[0m     average_intercept[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1622'>1623</a>\u001b[0m     loss_function,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1623'>1624</a>\u001b[0m     penalty_type,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1624'>1625</a>\u001b[0m     alpha,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1625'>1626</a>\u001b[0m     C,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1626'>1627</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1627'>1628</a>\u001b[0m     dataset,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1628'>1629</a>\u001b[0m     validation_mask,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1629'>1630</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1630'>1631</a>\u001b[0m     validation_score_cb,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1631'>1632</a>\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter_no_change),\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1632'>1633</a>\u001b[0m     max_iter,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1633'>1634</a>\u001b[0m     tol,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1634'>1635</a>\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept),\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1635'>1636</a>\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose),\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1636'>1637</a>\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshuffle),\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1637'>1638</a>\u001b[0m     seed,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1638'>1639</a>\u001b[0m     \u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1639'>1640</a>\u001b[0m     \u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1640'>1641</a>\u001b[0m     learning_rate_type,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1641'>1642</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meta0,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1642'>1643</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower_t,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1643'>1644</a>\u001b[0m     \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1644'>1645</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt_,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1645'>1646</a>\u001b[0m     intercept_decay,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1646'>1647</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maverage,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1647'>1648</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1649'>1650</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/linear_model/_stochastic_gradient.py?line=1651'>1652</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maverage \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dfGreen = pd.read_csv(\"taxi_data/green_tripdata_2019_concat.csv\", chunksize=50000)\n",
    "dfYellow = pd.read_csv(\"taxi_data/yellow_tripdata_2019_concat.csv\", chunksize=10000)\n",
    "\n",
    "model = SGDRegressor()\n",
    "\n",
    "poly = PolynomialFeatures(degree=12, include_bias=False)\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "counter = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for chunk in dfYellow:\n",
    "\n",
    "    X_green = chunk[[\"PU_start\", \"PUlat\", \"PUlong\",\"DOlat\", \"DOlong\"]] # input cols\n",
    "    y_green = chunk[[\"travel_time\"]] # output cols\n",
    "    \n",
    "    scaled = poly.fit_transform(min_max.fit_transform(X_green.values))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled, y_green.values.ravel(), test_size = 0.25)\n",
    "\n",
    "    model.partial_fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(str(counter) + \": Mean squared error: \" + str(mean_squared_error(y_test, y_pred)) + \" Accuracy: \" + str(score))\n",
    "    if score > best_accuracy:\n",
    "        print(\"New best accuracy\")\n",
    "        save_model(model, poly, min_max)\n",
    "        best_accuracy = score\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
