{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "lookup_df = pd.read_csv(\"zone_lookup.csv\")\n",
    "\n",
    "DATEPARSE = \"%Y-%m-%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "### Add data into /taxi_data/\n",
    "### Github stores a sample file of this. Download the rest and do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_minutes(_today):\n",
    "    return (_today.hour*60) + (_today.minute)\n",
    "def add_zero_padding(number):\n",
    "    if len(str(number)) == 1: return \"0\" + str(number)\n",
    "    else: return number\n",
    "def format_df(DF, pickup_date_column, dropof_date_column, month):\n",
    "    #Clean some rows where the location id is invalid\n",
    "    DF = DF[((DF[\"PULocationID\"] != 264) & (DF[\"PULocationID\"] != 265)) & ((DF[\"DOLocationID\"] != 264) & (DF[\"DOLocationID\"] != 265))]\n",
    "\n",
    "    start = pd.to_datetime(DF[pickup_date_column])\n",
    "    stop = pd.to_datetime(DF[dropof_date_column])\n",
    "    DF['travel_time'] = (stop - start).astype('timedelta64[m]').astype('int64')\n",
    "\n",
    "    DF = DF[(DF[\"travel_time\"] < 5*60)]\n",
    "\n",
    "    DF['PU_start'] = (start).dt.hour\n",
    "\n",
    "    DF['PUlat'] = DF.PULocationID.map(lookup_df.set_index('LocationID').lat)\n",
    "    DF['PUlong'] = DF.PULocationID.map(lookup_df.set_index('LocationID').long)\n",
    "    DF['DOlat'] = DF.DOLocationID.map(lookup_df.set_index('LocationID').lat)\n",
    "    DF['DOlong'] = DF.DOLocationID.map(lookup_df.set_index('LocationID').long)\n",
    "\n",
    "    DF['distance'] = ((DF.PUlat - DF.DOlat) ** 2 + (DF.PUlong - DF.DOlong) ** 2) ** 0.5\n",
    "\n",
    "    DF = DF.drop(columns=[dropof_date_column, pickup_date_column])\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv: 1\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 1\n",
      "Reading csv: 2\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 2\n",
      "Reading csv: 3\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 3\n",
      "Reading csv: 4\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 4\n",
      "Reading csv: 5\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 5\n",
      "Reading csv: 6\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 6\n",
      "Reading csv: 7\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 7\n",
      "Reading csv: 8\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 8\n",
      "Reading csv: 9\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 9\n",
      "Reading csv: 10\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 10\n",
      "Reading csv: 11\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 11\n",
      "Reading csv: 12\n",
      "Formating csv\n",
      "Writing csv\n",
      "DONE: 12\n"
     ]
    }
   ],
   "source": [
    "#dataset = (\"taxi_data/green_tripdata_2019\", \"l\")\n",
    "dataset = (\"taxi_data/yellow_tripdata_2019\", \"t\")\n",
    "\n",
    "header = True\n",
    "for x in range(1, 13): # this takes 5 min\n",
    "    try:\n",
    "        print(\"Reading csv: \" + str(x))\n",
    "        dfGreen = pd.read_csv(dataset[0] + \"-\" + str(add_zero_padding(x)) + \".csv\", usecols=[\"PULocationID\", \"DOLocationID\", dataset[1] + \"pep_pickup_datetime\", dataset[1] + \"pep_dropoff_datetime\"])\n",
    "        print(\"Formating csv\")\n",
    "        dfGreen = format_df(dfGreen, dataset[1] + \"pep_pickup_datetime\", dataset[1] + \"pep_dropoff_datetime\", x)\n",
    "        print(\"Writing csv\")\n",
    "        dfGreen.to_csv(dataset[0] + \"_concat.csv\", mode='a+', header=header, index=False)\n",
    "        header=False\n",
    "        print(\"DONE: \" + str(x))\n",
    "    except Exception as f:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 85.17 Accuracy:  0.026234531108630166\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rackaracka\\Documents\\repos\\ML\\Labb3\\Predict travel time.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/Predict%20travel%20time.ipynb#ch0000006?line=13'>14</a>\u001b[0m y_green \u001b[39m=\u001b[39m chunk[[\u001b[39m\"\u001b[39m\u001b[39mtravel_time\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m# output cols\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/Predict%20travel%20time.ipynb#ch0000006?line=15'>16</a>\u001b[0m scaled \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39mfit_transform(min_max\u001b[39m.\u001b[39mfit_transform(X_green\u001b[39m.\u001b[39mvalues))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/Predict%20travel%20time.ipynb#ch0000006?line=17'>18</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(scaled, y_green\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel(), test_size \u001b[39m=\u001b[39;49m \u001b[39m0.25\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/Predict%20travel%20time.ipynb#ch0000006?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mpartial_fit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rackaracka/Documents/repos/ML/Labb3/Predict%20travel%20time.ipynb#ch0000006?line=21'>22</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2443\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2438'>2439</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2440'>2441</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2442'>2443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2443'>2444</a>\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2444'>2445</a>\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2445'>2446</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2446'>2447</a>\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2445\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2438'>2439</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2440'>2441</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2442'>2443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2443'>2444</a>\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2444'>2445</a>\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2445'>2446</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/sklearn/model_selection/_split.py?line=2446'>2447</a>\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:378\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/sklearn/utils/__init__.py?line=375'>376</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/sklearn/utils/__init__.py?line=376'>377</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/sklearn/utils/__init__.py?line=377'>378</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/sklearn/utils/__init__.py?line=378'>379</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/sklearn/utils/__init__.py?line=379'>380</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dfGreen = pd.read_csv(\"taxi_data/green_tripdata_2019_concat.csv\", chunksize=50000)\n",
    "dfYellow = pd.read_csv(\"taxi_data/yellow_tripdata_2019_concat.csv\", chunksize=50000)\n",
    "\n",
    "model = SGDRegressor()\n",
    "\n",
    "poly = PolynomialFeatures(degree=9, include_bias=False)\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for chunk in dfYellow:\n",
    "\n",
    "    X_green = chunk[[\"PU_start\", \"PUlat\", \"PUlong\",\"DOlat\", \"DOlong\", \"distance\"]] # input cols\n",
    "    y_green = chunk[[\"travel_time\"]] # output cols\n",
    "    \n",
    "    scaled = poly.fit_transform(min_max.fit_transform(X_green.values))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled, y_green.values.ravel(), test_size = 0.25)\n",
    "\n",
    "    model.partial_fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Mean squared error: %.2f Accuracy: %.2f\" % mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        dump(model, \"models/\" + str(counter) + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2985.58207469]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "lpep_pickup_datetime,PULocationID,DOLocationID,month\n",
    "\"\"\"\n",
    "copied_from_green = [2949,2964,166,142,13.7648363727615,1.0]\n",
    "\n",
    "inputdata = [copied_from_green[0], copied_from_green[2], copied_from_green[3], copied_from_green[4], copied_from_green[5]]\n",
    "outputdata = [copied_from_green[1]]\n",
    "\n",
    "inputdata = [5469,41,74,1.0]\n",
    "outputdata = [5475]\n",
    "pred = model.predict([\n",
    "    inputdata\n",
    "])\n",
    "\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
